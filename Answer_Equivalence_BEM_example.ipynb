{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Answer Equivalence BEM example\n",
        "\n",
        "Copyright 2022 Google LLC.\n",
        "SPDX-License-Identifier: Apache-2.0"
      ],
      "metadata": {
        "id": "OvXQXJhPtnwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies.\n",
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BiTKIckQxwjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aAdYF4oXtm_9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports.\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "import numpy as np\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sets up the BERT tokenizer using tf-text.\n",
        "\n",
        "VOCAB_PATH = 'gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12/vocab.txt'  #@param {type:\"string\"}\n",
        "\n",
        "vocab_table = tf.lookup.StaticVocabularyTable(\n",
        "        tf.lookup.TextFileInitializer(\n",
        "            filename=VOCAB_PATH,\n",
        "            key_dtype=tf.string,\n",
        "            key_index=tf.lookup.TextFileIndex.WHOLE_LINE,\n",
        "            value_dtype=tf.int64,\n",
        "            value_index=tf.lookup.TextFileIndex.LINE_NUMBER\n",
        "        ), \n",
        "        num_oov_buckets=1)\n",
        "cls_id, sep_id = vocab_table.lookup(tf.convert_to_tensor(['[CLS]', '[SEP]']))\n",
        "tokenizer = text.BertTokenizer(vocab_lookup_table=vocab_table, \n",
        "                               token_out_type=tf.int64, \n",
        "                               preserve_unused_token=True, \n",
        "                               lower_case=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NND0honxyDaJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper functions for converting examples to BERT inputs.\n",
        "\n",
        "def bertify_example(example):\n",
        "  question = tokenizer.tokenize(example['question']).merge_dims(1, 2)\n",
        "  reference = tokenizer.tokenize(example['reference']).merge_dims(1, 2)\n",
        "  candidate = tokenizer.tokenize(example['candidate']).merge_dims(1, 2)\n",
        "\n",
        "  input_ids, segment_ids = text.combine_segments(\n",
        "      (candidate, reference, question), cls_id, sep_id)\n",
        "\n",
        "  return {'input_ids': input_ids.numpy(), 'segment_ids': segment_ids.numpy()}\n",
        "\n",
        "\n",
        "def pad(a, length=512):\n",
        "  return np.append(a, np.zeros(length - a.shape[-1], np.int32))\n",
        "\n",
        "\n",
        "def bertify_examples(examples):\n",
        "  input_ids = []\n",
        "  segment_ids = []\n",
        "  for example in examples:\n",
        "    example_inputs = bertify_example(example)\n",
        "    input_ids.append(pad(example_inputs['input_ids']))\n",
        "    segment_ids.append(pad(example_inputs['segment_ids']))\n",
        "\n",
        "  return {'input_ids': np.stack(input_ids), 'segment_ids': np.stack(segment_ids)}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "S_4PBlU5yj3f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BEM model.\n",
        "bem = hub.load('https://tfhub.dev/google/answer_equivalence/bem/1')\n"
      ],
      "metadata": {
        "id": "rXfyQIf8YAR5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [{\n",
        "    'question': 'why is the sky blue',\n",
        "    'reference': 'light scattering',\n",
        "    'candidate': 'scattering of light'\n",
        "    }]\n",
        "\n",
        "inputs = bertify_examples(examples)\n",
        "\n",
        "# The outputs are raw logits.\n",
        "raw_outputs = bem(inputs)\n",
        "\n",
        "# They can be transformed into a classification 'probability' like so:\n",
        "bem_score = float(softmax(np.squeeze(raw_outputs))[1])\n",
        "\n",
        "print(f'BEM score: {bem_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XneLDE9YYViA",
        "outputId": "50b2ff4b-cac9-49c1-e9ec-e29b06ef8cdf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEM score: 0.9891803860664368\n"
          ]
        }
      ]
    }
  ]
}